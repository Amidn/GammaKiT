.. include:: ../../references.txt

.. _pig-011:

*********************
PIG 11 - Light curves
*********************

* Author: RÃ©gis Terrier, Christoph Deil, Axel Donath, David Fidalgo
* Created: July 2, 2018
* Accepted:
* Status: draft
* Discussion: `GH 1451`_

Abstract
========

In this PIG we want to discuss a restructuring of the way light curves are
computed and stored in Gammapy. Lightcurves in gamma-ray astronomy are the
result of a series of fits of the source flux in each time bin. Lightcurve
extraction covers therefore both the data reduction and the data modeling steps.
The lightcurve estimation will therefore have these two steps.

Here, we propose to perform the data reduction step in each of the time bins
and store the result in the form of a ``Datasets`` (``MapDataset`` or
``SpectrumOnOffDataset`` depending on the selected approach).
Each individual ``Dataset`` is then modeled and fitted to extract the
source flux and its errors in each time bin. The result is then stored in a
``LightCurve`` object which contains a ``Table`` of the fit results.

For this purpose, we propose to introduce two new classes to perform the data
reduction first and then then the fitting. The time dependent data reduction
could be a specific case of the high level pipeline, when a list of time bins
is passed with the configuration ``dict``. The data fitting should be performed
by the new :class:``LightCurveEstimator`` class, which  should essentially be a
wrapper around the ``gammapy.spectrum.FluxPointEstimator`` class that does the same
thing for spectrum and map datasets.

Introduction
============

Lightcurves in gamma-ray astronomy
----------------------------------

In photon counting experiments, lightcurves are often simply obtained by counting
events in a given energy range in a set of time bins. In ground based gamma-ray
astronomy, things are usually more complex.

The response and the instrumental background of the instruments can strongly vary
over time on a night scale, e.g. because the source elevation changes or on longer time
scales given the possible changes of the atmosphere transparency or the instrument
efficiency.

Another complexity comes from the astrophysical background which can often pollute a source
and needs to be properly removed to extract the intrinsic source flux at any given time.

For these reasons, gamma-ray lightcurve are usually the results of a fit of model on
the data performed on a number of time bins to extract the source flux in these time
bins.

This is more limited than e.g. time resolved spectral analysis. Although the latter share
many similarities with the lightcurve extraction, it is a more complex task which
we do not cover here.

Background / What we have now
-----------------------------

The current :class:``gammapy.time.LightCurveEstimator`` class assumes that a
part of the data reduction process has already been applied at it takes as input a
:class:``gammapy.spectrum.SpectrumExtraction`` instance for which a list of
:class:``gammapy.background.BackgroundEstimate`` is required. Apart from the time
intervals, the user also has to provide a ``gammapy.spectrum.SpectralModel`` that
is used to compute the expected counts in a time bin and to scale the integral
flux with respect to the excess events found in that time bin. The parameters of
the spectral model are generally obtained via a spectral fit to the whole data
sample. A tutorial notebook of this approach can be found `here
<http://docs.gammapy.org/dev/notebooks/light_curve.html>`_.

Drawbacks of this approach are:
 * there is no clear separation of the data reduction and modeling steps
 * only 1D On-Off spectral analysis is supported and lacks supports for
``MapDataset`` based analysis.
 * changes in the spectral shape between the time bins are not supported.


Proposal
========

General organization of the new approach
----------------------------------------

The approach will be split into 3 main phases:
 * Time bin preparation
 * Data reduction in time bins to produce a list of ``Dataset``
 * Light curve estimation to fit a model on the resulting ``Datasets``
The end product should contain enough information to perform some rebinning and apply
high level timing techniques without rerunning the whole data reduction and fitting steps.

Time bin preparation
--------------------

Independently of the actual data reduction technique chosen, the user should
first provide a list/table of time intervals for which she/he
wants to compute the source flux. The computation of this list/table will be
done outside of the light curve estimation class.

While we could provide helper functions to prepare the time bins. ``astropy.time.Time``
is relatively easy to use, so that a user would execute code similar to the following
example::

    from astropy.time import Time
    time_start = Time("2006-07-29 20:00:00.000")
    time_step = 5.0 * u.min
    nstep = 120
    times = time_start + time_step * np.arange(nstep)
    time_bins = []
    for tmin, tmax in zip(times, times[1:]):
        time_bins.append((tmin,tmax))

Data reduction
--------------

Once the time bins are determined, the user will have to select the relevant
``Observations`` from the ``Datastore``. The ``Observations`` are then filtered
and grouped according to the time bins using the ``ObservationFilter`` and passed
to the light curve extraction function or class.
The latter could take a ``geom`` or a ``region`` argument that will define the data
reduction geometry (and in particular, if the data reduction is 3D or 1D). In the
absence, of a ``RegionGeom`` we could simply expect a reco energy and true energy
``MapAxis``.

Because of the OFF determination, spectral and ``Map`` based data reduction cannot
be performed in a completely similar manner. We detail possible approaches below.

Both approaches will result in a ``Datasets`` object consisting of ``MapDataset``
or ``SpectrumDatasetOnOff`` with identical geometries for each time bin.
The ``Dataset`` must therefore carry the time information. Minimally, with a meta
information ``time_start``, ``time_stop``. Ideally, the ``Dataset`` should contain
 the ``GTI`` table of the filtered ``Eventlist`` that were used for its production.

Outline of the implementation in 3D
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Overall, the user could apply the following code::

    from gammapy.time import MapLightCurveMaker
    from gammapy.data import Observations, ObservationFilter , DataStore

    observations = datastore.get_observations(obs_ids)
    position = SkyCoord(0,0, unit='deg', frame='icrs')

    energy_axis = MapAxis.from_bounds(0.1, 10., 10, unit="TeV", name="energy", interp="log")
    geom = WcsGeom.create(skydir=position, binsz=0.02, width=(4, 4), axes=[energy_axis])

    datasets = MapLightCurveMaker(observations, geom, time_bins)

Inside ``MapLightCurveMaker`` one would then perform the following operations::

    def MapLightCurveMaker(observations, geom , time_bins):
        LC_datasets = []

        for time in time_bins:
            # Here we simply get the observations in a time bin
            obs = observations.select_time(time)

            maker = MapMaker(geom, offset_max = 2*u.deg)
            res = maker.run(obs)
            LC_datasets.append(res)

        return LC_datasets

Outline of the new implementation in 1D
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

In 1D the implementation is somewhat different, we should have something like::

    from gammapy.time import SpectrumLightCurveMaker
    from gammapy.data import Observations, ObservationFilter , DataStore

    observations = datastore.get_observations(obs_ids)
    position = SkyCoord(0,0, unit='deg', frame='icrs')

    energy_axis = MapAxis.from_bounds(0.1, 10., 10, unit="TeV", name="energy", interp="log")
    on_region = CircleSkyRegion(position, "0.11 deg")

    datasets = SpectrumLightCurveMaker(observations, on_region, energy_axis , time_bins)

Inside ``SpectrumLightCurveMaker`` one would then perform the following operations::

    def SpectrumLightCurveMaker(observations, on_region, energy_axis , time_bins):
        LC_datasets = []
        bkg_estimator = ReflectedRegionsBackgroundMaker(observations=self.observations, on_region=on_region)
        bkg_estimator.run()

        for time in time_bins:
            # Here we simply get the observations in a time bin
            obs = observations.select_time(time)
            # The event filtering has to be performed on the background events
            bkg_estimates = bkg_estimator.select_time_on(time)
            spec = Spectrum_Extraction(obs, bkg_estimates)
            spec.run()
            LC_datasets.append(spec.spectrum_observations)

        return LC_datasets

The main missing ingredient here is a function to apply to the ``ReflectedRegionsBackgroundMaker``
results. It should apply the time filter to the ``BackgroundEstimate.on_events`` and modify the
``BackgroundEstimate.a_on`` and ``BackgroundEstimate.a_off`` accordingly.

Data Fitting
------------

The data fitting is the step were the ``Datasets`` are converted into a lightcurve
based on a model of the emission. The amplitude of the source model is fitted while
other parameters are usually, but not necessarily, fixed.

The fitting is very similar to the extraction of ``FluxPoints`` in the spectral analysis
and does not strongly depend on the type of ``Datasets`` considered. The new
:class:``LightCurveEstimator`` class should therefore be able to take as input both
``SpectrumDatasetOnOff`` and ``MapDataset``, in a similar fashion as the current
``FluxPointEstimator``.


Storing the results and further studies
---------------------------------------

The results are returned as a ``gammapy.time.LightCurve`` instance (the current
container class for light curves) that, so far, essentially holds the integrated flux +
errors and the time_min/time_max of each time bin. There are many other quantities
which could be stored, such as the energy range of the flux, the number of excess
events in the time bin considered, etc.
The current container class already provides some methods to study variability, such as
chi-square test, fractional variance estimation. But these methods are more general
than the specific case of gammapy.


Discussion / Alternatives
=========================

Time bins
^^^^^^^^^

To work with time bins, we could also rely on ``astropy.timeseries`` if we force the dependency to astropy v>3.2.
This would look like::

    from astropy.timeseries import BinnedTimeSeries
    times = BinnedTimeSeries(time_bin_start="2006-07-29 20:00:00.000",
                           time_bin_size=5 * u.min)
    print(times.time_bin_start)
    print(times.time_bin_end)

Lightcurve
^^^^^^^^^^
The ``Lightcurve`` contains  an ``astropy.table.Table`` object. It could
be improved by using the ``astropy_timeseries.BinnedTimeSeries`` object which
itself inherits from ``QTable`` and provides support for row selection with time,
rebinning and more complex methods for detailed timing studies such as Lomb-Scargle
periodograms.

Task list
=========

 * Add `TSTART` and `TSTOP` meta info on the ``Dataset`` as well as the `GTI` table.
 * Introduce `GTI.union()` method to merge `Datasets`.
 * Refactor the ``Lightcurve`` class to add a number of new content in the `Table` e.g.
a `fit_stat_scan` column.
 * Implement the new ``LightCurveEstimator`` class

Decision
========

tbd

.. _GH 1451: https://github.com/gammapy/gammapy/pull/1451
.. _good time interval: http://heasarc.gsfc.nasa.gov/docs/heasarc/ofwg/docs/rates/ogip_93_003/ogip_93_003.html#tth_sEc6.3

