.. include:: ../../references.txt

.. _pig-011:

*********************
PIG 11 - Light curves
*********************

* Author: Christoph Deil, RÃ©gis Terrier, Axel Donath, David Fidalgo
* Created: July 2, 2018
* Accepted:
* Status: draft
* Discussion: `GH 1451`_

Abstract
========

In this PIG we want to discuss a restructuring of the way light curves are
computed and stored in Gammapy. Lightcurves in gamma-ray astronomy are the
result of a series of fits in each time bin. Lightcurve extraction covers
therefore both the data reduction and the data modeling steps. The lightcurve
estimation will therefore have these two steps.
Here, we propose to perform the data reduction step in each of the time bins
and store the result in the form of a `Datasets` (`MapDataset` or
`SpectrumOnOffDataset` depending on the selected approach).
Each individual `Dataset` is then modeled and fitted to extract the
source flux and its errors in each time bin. The result is then stored in a
`LightCurve` object .
For this purpose, the new :class:`LightCurveEstimator` class should essentially be a
wrapper around the *standard* spectrum analysis of Gammapy using pipeline
classes (e.g. `gammapy.scripts.SpectrumAnalysisIACT`). A further input should of
course be the time intervals of the light curve, whose computation will be done
outside of the new `LightCurve` classes.

Detailed Description
====================

Background / What we have now
-----------------------------

The current :class:`gammapy.time.LightCurveEstimator` class assumes that a
part of the data reduction process has already been applied at it takes as input a
:class:`gammapy.spectrum.SpectrumExtraction` instance for which a list of
:class:`gammapy.background.BackgroundEstimate` is required. Apart from the time
intervals, the user also has to provide a `gammapy.spectrum.SpectralModel` that
is used to compute the expected counts in a time bin and to scale the integral
flux with respect to the excess events found in that time bin. The parameters of
the spectral model are generally obtained via a spectral fit to the whole data
sample. A tutorial notebook of this approach can be found `here
<http://docs.gammapy.org/dev/notebooks/light_curve.html>`_.

Drawbacks of this approach are:
 * there is no clear separation of the data reduction and modeling steps
 * only 1D On-Off spectral analysis is supported and lacks supports for
`MapDataset` based analysis.
 * changes in the spectral shape between the time bins are not supported.


General organization of the new approach
----------------------------------------

Time bin preparation
^^^^^^^^^^^^^^^^^^^

Independently of the actual data reduction technique chosen, the user should
first provide a list/table of time intervals for which she/he
wants to compute the source flux. The computation of this list/table will be
done outside of the light curve estimation class.

We could provide helper functions to prepare the time bins. So that, typically,
a user would execute the following code::

    from astropy.time import Time
    time_start = Time("2006-07-29 20:00:00.000")
    time_stop = Time("2006-07-30 06:00:00.00")
    time_step = 5.0 * u.min
    time_bins = constant_time_bins(time_start, time_stop, time_step)

Alternatively, we could rely on `astropy.timeseries` if we force the dependency to astropy v>3.2.
This would look like::

    from astropy.timeseries import BinnedTimeSeries
    times = BinnedTimeSeries(time_bin_start="2006-07-29 20:00:00.000",
                           time_bin_size=5 * u.min)
    print(times.time_bin_start)
    print(times.time_bin_end)

Data reduction
^^^^^^^^^^^^^^

Once the time bins are determined, the user will have to select the relevant
`Observations` from the `Datastore`, with, if needed, the application of some
`ObservationFilter` to the `EventList`. The `Observations` are then passed along
the time bins to the light curve estimation class `LightCurveEstimator`. The
latter could take a `geom` argument that will define the data reduction
geometry (and in particular, if the data reduction is 3D or 1D). In the absence, of a
`RegionGeom` we could simply expect a reco energy and true energy `MapAxis`.

Because of the OFF determination, spectral and `Map` based data reduction cannot be performed
in a completely similar manner. We detail possible approaches below.

Both approaches will result in a `Datasets` object consisting of `MapDataset`
or `SpectrumDatasetOnOff` with identical geometries for each time bin.
The `Dataset` must therefore carry the time information. Minimally, with a meta
information `time_start`, `time_stop`. Ideally, the `Dataset` should contain
 the `GTI` table of the filtered `Eventlist` that were used for its production.

Data Fitting
^^^^^^^^^^^^

TBD

Storing the results and timing studies
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The results are returned as a `gammapy.time.LightCurve` instance (the current
container class for light curves) that, so far, essentially holds the integrated flux +
errors and the time_min/time_max of each time bin. There are many other quantities
which could be stored, such as the energy range of the flux, the number of excess
events in the time bin considered, etc. In particular, for lightcurves with spectral
variability studies, columns for other model parameters and associated errors would
be necessary.
The current container class already provides some methods to study variability, such as
chi-square test, fractional variance estimation. But these methods are more general
than the specific case of gammapy.

This container is based on an `astropy.table.Table` object. It could therefore
be improved by using the `astropy_timeseries.BinnedTimeSeries` object which
itself inherits from `Table` and provides support for row selection with time,
rebinning and more complex methods for detailed timing studies such as Lomb-Scargle
periodograms.


Outline of the implementation in 3D
-----------------------------------

TBD


Outline of the new implementation in 1D
---------------------------------------

TBC

In the new approach we want to overcome the two drawbacks mentioned above and
provide a maximum degree of flexibility to the user when computing the light
curve.

First, the user should provide a list/table of time intervals for which she/he
wants to compute the integral flux. The computation of this list/table will be
done outside of the `LightCurve` class, e.g. we could think about extending the
`gammapy.data.gti` class to provide some utilities for this.

With this list/table the new `LightCurveEstimator` should then prepare/create a
new `~gammapy.data.ObservatioList` for each time bin, in which the events have
already been filtered properly and the
`DataStoreObservation.observation_live_time_duration` were updated accordingly.
These new `~gammapy.data.ObservationList` can then be passed on to the
*standard* spectrum analysis with the `gammapy.background` and
`gammapy.spectrum` modules.

This analysis pipeline should be done outside of the LightCurve class, for
example by `gammapy.scripts.SpectrumAnalysisIACT`. The arguments for this
pipeline should be provided in form of a *config dict* or possibly a txt file.
One could think about providing a list of *config dict* or txt files to have
more flexibility when performing the pipeline in each of the time bins.

Instead of performing a spectral fit in each time bin, the user should also have
the option to provide a fixed spectral shape, omit the fit and compute the
integral flux the way it is done now, by scaling the expected counts with
respect to the excess events, which should be much faster.



Calling the spectral pipeline for each time bin
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

After preparing the observations and writing them to disk, a loop over the light
curve bins should create a `~gammapy.data.DataStore` object ->
`~gammapy.data.ObservationList` and pass it on to the spectral pipeline (e.g.
`gammapy.scripts.SpectrumAnalysisIACT`). Maybe the option to omit the spectral
fit and scale a fixed spectrum to the excess counts, should be built in the
pipeline classes. The resulting spectrum of the time bin is then integrated in
an energy range specified by the user.




Discussion / Alternatives
=========================

The outline described above would require changes in the
`gammapy.data.data_store`, `gammapy.time.lightcurve` and
`gammapy.scripts.SpectrumAnalysisIACT` modules. The `gammapy.background` and
`gammapy.spectrum` modules would remain unchanged.

Instead of preparing new `~gammapy.data.ObservationList` for each time bin,
which leaves the filtering/selection of the events and IRFs to the
`LightCurveEstimator` class, we could also do the filtering/selection in the
`~gammapy.background` and `~gammapy.spectrum` modules by means of the GTI table
(`good time interval`_) already present in the
`gammapy.data.DataStoreObservation` object. At the moment this table is not used
at all. A drawback of this approach would be the necessity of changes in the
`~gammapy.background` and `~gammapy.spectrum` modules. Even though i have not
worked out any specifics of this approach yet, i think this would be a less
elegant way. 

Task list
=========

tbd

Decision
========

tbd

.. _GH 1451: https://github.com/gammapy/gammapy/pull/1451
.. _good time interval: http://heasarc.gsfc.nasa.gov/docs/heasarc/ofwg/docs/rates/ogip_93_003/ogip_93_003.html#tth_sEc6.3

