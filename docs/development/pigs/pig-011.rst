.. include:: ../../references.txt

.. _pig-011:

*********************
PIG 11 - Light curves
*********************

* Author: Christoph Deil, RÃ©gis Terrier, Axel Donath, David Fidalgo
* Created: July 2, 2018
* Accepted:
* Status: draft
* Discussion: `GH 1451`_

Abstract
========

In this PIG we want to discuss a restructuring of the way light curves are
computed and stored in Gammapy. Lightcurves in gamma-ray astronomy are the
result of a series of fits in each time bin. Lightcurve extraction covers
therefore both the data reduction and the data modeling steps. The lightcurve
estimation will therefore have these two steps.
Here, we propose to perform the data reduction step in each of the time bins
and store the result in the form of a `Datasets` (`MapDataset` or
`SpectrumOnOffDataset` depending on the selected approach).
Each individual `Dataset` is then modeled and fitted to extract the
source flux and its errors in each time bin. The result is then stored in a
`LightCurve` object .
For this purpose, the new :class:`LightCurveEstimator` class should essentially be a
wrapper around the *standard* spectrum analysis of Gammapy using pipeline
classes (e.g. `gammapy.scripts.SpectrumAnalysisIACT`). A further input should of
course be the time intervals of the light curve, whose computation will be done
outside of the new `LightCurve` classes.

Detailed Description
====================

Background / What we have now
-----------------------------

The current :class:`gammapy.time.LightCurveEstimator` class assumes that a
part of the data reduction process has already been applied at it takes as input a
:class:`gammapy.spectrum.SpectrumExtraction` instance for which a list of
:class:`gammapy.background.BackgroundEstimate` is required. Apart from the time
intervals, the user also has to provide a `gammapy.spectrum.SpectralModel` that
is used to compute the expected counts in a time bin and to scale the integral
flux with respect to the excess events found in that time bin. The parameters of
the spectral model are generally obtained via a spectral fit to the whole data
sample. A tutorial notebook of this approach can be found `here
<http://docs.gammapy.org/dev/notebooks/light_curve.html>`_.

Drawbacks of this approach are:
 * there is no clear separation of the data reduction and modeling steps
 * only 1D On-Off spectral analysis is supported and lacks supports for
`MapDataset` based analysis.
 * changes in the spectral shape between the time bins are not supported.


General organization of the new approach
----------------------------------------

Time bin preparation
^^^^^^^^^^^^^^^^^^^

Independently of the actual data reduction technique chosen, the user should
first provide a list/table of time intervals for which she/he
wants to compute the source flux. The computation of this list/table will be
done outside of the light curve estimation class.

We could provide helper functions to prepare the time bins. So that, typically,
a user would execute the following code::

    from astropy.time import Time
    time_start = Time("2006-07-29 20:00:00.000")
    time_stop = Time("2006-07-30 06:00:00.00")
    time_step = 5.0 * u.min
    time_bins = constant_time_bins(time_start, time_stop, time_step)

Alternatively, we could rely on `astropy.timeseries` if we force the dependency to astropy v>3.2.
This would look like::

    from astropy.timeseries import BinnedTimeSeries
    times = BinnedTimeSeries(time_bin_start="2006-07-29 20:00:00.000",
                           time_bin_size=5 * u.min)
    print(times.time_bin_start)
    print(times.time_bin_end)

Data reduction
^^^^^^^^^^^^^^


Storing the results and timing studies
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The results are returned as a `gammapy.time.LightCurve` instance (the current
container class for light curves) that essentially holds the integrated flux +
errors and the time_min/time_max of each time bin. Other useful quantities which
are not stored right now, could be energy_min/energy_max of the integral flux.
This container class already provides some methods to study variability.

This container is based on an `astropy.table.Table` object. It could therefore
be improved by using the `astropy_timeseries.BinnedTimeSeries` object which
itself inherits from `Table` and provides support for row selection with time,
rebinning and more complex methods for detailed timing studies such as Lomb-Scargle
periodograms.


Outline of the new implementation in 1D
---------------------------------------

In the new approach we want to overcome the two drawbacks mentioned above and
provide a maximum degree of flexibility to the user when computing the light
curve.

First, the user should provide a list/table of time intervals for which she/he
wants to compute the integral flux. The computation of this list/table will be
done outside of the `LightCurve` class, e.g. we could think about extending the
`gammapy.data.gti` class to provide some utilities for this.

With this list/table the new `LightCurveEstimator` should then prepare/create a
new `~gammapy.data.ObservatioList` for each time bin, in which the events have
already been filtered properly and the
`DataStoreObservation.observation_live_time_duration` were updated accordingly.
These new `~gammapy.data.ObservationList` can then be passed on to the
*standard* spectrum analysis with the `gammapy.background` and
`gammapy.spectrum` modules.

This analysis pipeline should be done outside of the LightCurve class, for
example by `gammapy.scripts.SpectrumAnalysisIACT`. The arguments for this
pipeline should be provided in form of a *config dict* or possibly a txt file.
One could think about providing a list of *config dict* or txt files to have
more flexibility when performing the pipeline in each of the time bins.

Instead of performing a spectral fit in each time bin, the user should also have
the option to provide a fixed spectral shape, omit the fit and compute the
integral flux the way it is done now, by scaling the expected counts with
respect to the excess events, which should be much faster.


Preparing the ObservationList for each time bin
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The general idea is to write a new `~gammapy.data.ObservationList` for each time
bin to disk, so that they can be easily read-in by the DataStore class with, for
example, its `.from_dir()` method. This would avoid memory issues for large data
sets and the user also gets the possibility to easily repeat a spectral analysis
in one of the light curve bins. For this procedure
`~gammapy.data.ObservationList` should get a method like
`.write_to_disk(outdir)`, or the `~gammapy.data.DataStore` object should get a
method `.write_list_to_disk(obslist, outdir)` (invocation vs inspection).

Depending on the modifications planned for the `gammapy.data.data_store` module,
one could also think about providing the user with the option to do everything
in-memory, which could especially be useful for playing around/testing.

The preparation of the new `~gammapy.data.ObservationList` for each time bin
would then basically consist of 3 steps:
 * The `LightCurveEstimator` class figures out which observation belongs to
   which light curve bin and creates a new `~gammapy.data.ObservationList` with
   these observations for each time bin;
 * The new `~gammapy.data.ObservationList` are written to disk in a new folder
   structure specified by the user;
 * The LightCurve class modifies the event lists of the first and last (in 
   time) observation in the respective `~gammapy.data.ObservationList` and
   updates their `observation_live_time_duration` (what about the `GTI` s?).


Calling the spectral pipeline for each time bin
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

After preparing the observations and writing them to disk, a loop over the light
curve bins should create a `~gammapy.data.DataStore` object ->
`~gammapy.data.ObservationList` and pass it on to the spectral pipeline (e.g.
`gammapy.scripts.SpectrumAnalysisIACT`). Maybe the option to omit the spectral
fit and scale a fixed spectrum to the excess counts, should be built in the
pipeline classes. The resulting spectrum of the time bin is then integrated in
an energy range specified by the user.


Outline of the implementation in 3D
-----------------------------------

We still have not looked into this implementation. Maybe we should first workout
the 1D case and adopt the hopefully well-oiled solution to the 3D case.

Discussion / Alternatives
=========================

The outline described above would require changes in the
`gammapy.data.data_store`, `gammapy.time.lightcurve` and
`gammapy.scripts.SpectrumAnalysisIACT` modules. The `gammapy.background` and
`gammapy.spectrum` modules would remain unchanged.

Instead of preparing new `~gammapy.data.ObservationList` for each time bin,
which leaves the filtering/selection of the events and IRFs to the
`LightCurveEstimator` class, we could also do the filtering/selection in the
`~gammapy.background` and `~gammapy.spectrum` modules by means of the GTI table
(`good time interval`_) already present in the
`gammapy.data.DataStoreObservation` object. At the moment this table is not used
at all. A drawback of this approach would be the necessity of changes in the
`~gammapy.background` and `~gammapy.spectrum` modules. Even though i have not
worked out any specifics of this approach yet, i think this would be a less
elegant way. 

Task list
=========

tbd

Decision
========

tbd

.. _GH 1451: https://github.com/gammapy/gammapy/pull/1451
.. _good time interval: http://heasarc.gsfc.nasa.gov/docs/heasarc/ofwg/docs/rates/ogip_93_003/ogip_93_003.html#tth_sEc6.3

