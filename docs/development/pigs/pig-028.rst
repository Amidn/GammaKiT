. include:: ../../references.txt

.. _pig-028:

***************************************
PIG 28 - Metadata container for Gammapy
***************************************

* Author: RÃ©gis Terrier
* Created: April 14th, 2023
* Accepted: -
* Status: -
* Discussion:

Abstract
========

Metadata handling is crucial to correctly store information that are not directly data
but are still required for processing, post-processing and serialization. They are
fundamental for reproducibility.

Introduction
============

As of version 1.0, Gammapy has very little support for metadata. Existing features are
heterogeneous, hardly configurable and appear sporadically in the code, mostly in
containers. At the DL3 level, ``EventList`` metadata is carried by its `Table.meta` dictionary.
It is extracted from the  file FITS header which follows the GADF specifications.
Similarly, ``Observation`` contains an `obs_info` dictionary that is build from the header as well.
After data reduction, ``Dataset`` contains a `meta_table` which
consists in a selection of `Observation.obs_info` entries (one table row per observation).
During `Dataset` stacking the `meta_table` are stacked. The ``Datasets`` collection also
agregates the `meta_table` of its members. After estimation, the ``FluxPoints`` don't
contain any specific meta information.

The algorithm classes (`Makers` and `Estimators`) don't contain any meta information so far.
This might be an issue since some information  could be transfered on their various products
as well.

A minimal information that needs to be present on every Gammapy product and serialized
in various formats is the `CREATOR` which is the software and software version used,
as well as the `DATE` when the object was created, and possibly the `ORIGIN` (the user,
the consortium that has produced the object). The Gammapy version number is important to ensure
reproducibility and compatibility.

An `Observation` also needs some information to ensure correct handling of data. For instance,
the telescope name, the sub-array used, the observation mode, the telescope location etc.

A practical and systematic solution must be implemented in Gammapy. This PIG discusses
the approach and proposes a solution for this. It does not discuss the metadata model, i.e.
what information has to be stored on which data product. It proposes a basic concept and
a possible implementation of a metadata container object that fulfill the requirements.

Requirements
============

The Gammapy metadata solution should:

- offer flexibility regarding the content of the data model, e.g.:
    - it should allow optional entries
    - it should be configurable to allow for specific data models
- have a systematic validation of its content
- allow for serialization to various formats, e.g.:
    - export specific keywords to fits headers depending on the data format
    - export content to yaml
- allow hierarchical content to allow easy propagation of metadata content along the
  analysis flow
- be easily subscriptable to allow for specialized metadata containers for the various
  objects in Gammapy.

In the following, we propose a plausible solution fulfilling these requirements based on the
the `pydantic` package ``BaseModel`` class.


Metadata API
============

Type validation
---------------

The API should support simple validation on input, even for non standard types such as
astropy or Gammapy objects.

.. code ::

    # direct assignment
    >>> meta.zenith_angle = Angle(30, "deg")
    # or via a string representation
    >>> meta.zenith_angle = "30 deg"
    # input validation
    >>> meta.zenith_angle = 2*u.TeV
    ValidationError: 1 validation error for MetaData zenith_angle
    # attribute type is astropy Angle
    >>> print(meta.zenith_angle)
    30d00m00s


Serialization
-------------

The metadata classes should have a `to_dict()` or `dict()` method to convert their content
to a dictionary.

Conversion to various output formats should be supported with specific methods such as `to_yaml()`
of `to_header()` to export the content in the form of a FITS header, when possible.

Because we expect the number of data formats will increase over the years, specific `Reader`
and `Writer` functions or classes could be defined to support e.g. reading and writing
to gadf DL3 format.


Proposed solution
=================

pydantic
--------

The pydantic package has been built to perform data validation and settings management
using Python type annotations. It enforces type hints at runtime, and provides user friendly
errors when data is invalid.

It offers nice features such as:
- it can be extended to custom data types (e.g. a `Quantity` or a `Map`) with a simple
  decorator based scheme to define validators.
- it supports recursive models

The package now extremely widely used in the python ecosystem with more than 50 millions
monthly Pypi downloads. Its long-term viability does not appear problematic.

Gammapy already uses pydantic for its high level analysis configuration class.

There are several other options available such as `traitlets`. The latter also allows the
addition of user-defined `TraitType`.

the base class
--------------

A typical base class for all Gammapy metadata could structured following the structure below:

.. code ::

    class MetaDataBaseModel(BaseModel):
        class Config:
            arbitrary_types_allowed = True
            validate_all = True
            validate_assignment = True
            extra = "allow"

        def to_header(self):
            hdr_dict = {}
            for key, item in self.dict().items():
                hdr_dict[key.upper()] = item.__str__()
            return hdr_dict

        @classmethod
        def from_header(cls, hdr):
            kwargs = {}
            for key in cls.__fields__.keys():
                kwargs[key] = hdr.get(key.upper(), None)
            return cls(**kwargs)

The model `Config` defined allows:
- using any type input and not only simple `Annotation` types (`arbitrary_types_allowed = True`)
- Setting the `validate_assignment` to `True` ensures that validation is performed when a value
  is assigned to the attribute.
- `extra = "allow"` accepts additional attibutes not defined in the metadata class.




arbitrary type input and validation
-----------------------------------

.. code ::

    class ArbitraryTypeMetaData(MetaDataBaseModel):
        # allow string defining angle or Angle object
        zenith_angle : Optional[Union[str, Angle]]
        pointing_altaz : Union[]

        # allow observatory name or astropy EarthLocation object
        location : Optional[Union[str, EarthLocation]]

        @validator('location')
        def validate_location(cls, v):
            if isinstance(v, str) and v in observatory_locations.keys():
                return observatory_locations[v]
            elif isinstance(v, EarthLocation):
                return v
            else:
                raise ValueError("Incorrect location value")

        @validator('zenith_angle')
        def validate_zenith_angle(cls, v):
            return Angle(v)


Alternatives
============

Decision
========

