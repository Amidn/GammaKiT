{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ring Background Estimation\n",
    "\n",
    "## Context:\n",
    "Classically, image analysis in IACT have often relied on the ring background model to get a background estimate. This method typically involves extracting a ring around a trial source position to estimate the background strength. To correct for the varying camera acceptance within the field of view, an acceptance correction function is used to compute the normalisation for each position of the ring. To read more about this method, see [here.](https://arxiv.org/abs/astro-ph/0610959)\n",
    "\n",
    "## Proposed approach:\n",
    "\n",
    "The analysis workflow is roughly\n",
    " - Compute the sky maps keeping each observation separately using the `Analysis` class\n",
    " - Estimate the background using the `RingBackgroundMaker`\n",
    " - Compute significance and excess maps using `compute_lima_on_off_image`\n",
    " \n",
    "The Li&Ma images thus computed can be used for normal modelling and fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "As usual, we'll start with some general imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from regions import CircleSkyRegion\n",
    "from astropy.convolution import Tophat2DKernel\n",
    "from scipy.stats import norm\n",
    "\n",
    "import logging\n",
    "\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import gammapy specific classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammapy.analysis import Analysis, AnalysisConfig\n",
    "from gammapy.cube import RingBackgroundMaker, MapDatasetOnOff\n",
    "from gammapy.detect import compute_lima_on_off_image\n",
    "from gammapy.maps import Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the config file\n",
    "Now, we create a config file for out analysis. You may load this from disc if you have a pre-defined config file.\n",
    "\n",
    "In this example, we will use a few HESS runs on the pulsar wind nebula, MSH 1552"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_pos = SkyCoord.from_name(\"MSH 15-52\")\n",
    "source_pos = SkyCoord(228.32, -59.08, unit=\"deg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AnalysisConfig()\n",
    "# Select observations - 2.5 degrees from the source position\n",
    "config.observations.datastore = \"$GAMMAPY_DATA/hess-dl3-dr1/\"\n",
    "config.observations.obs_cone = {\n",
    "    \"frame\": \"icrs\",\n",
    "    \"lon\": source_pos.ra,\n",
    "    \"lat\": source_pos.dec,\n",
    "    \"radius\": 2.5 * u.deg,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.datasets.type = \"3d\"\n",
    "config.datasets.geom.wcs.skydir = {\n",
    "    \"lon\": source_pos.ra,\n",
    "    \"lat\": source_pos.dec,\n",
    "    \"frame\": \"icrs\",\n",
    "}  # The WCS geometry - centered on MSH 15-52\n",
    "config.datasets.geom.wcs.fov = {\"width\": \"3 deg\", \"height\": \"3 deg\"}\n",
    "config.datasets.geom.wcs.binsize = \"0.02 deg\"\n",
    "\n",
    "# The FoV offset cut\n",
    "config.datasets.geom.selection.offset_max = 3.5 * u.deg\n",
    "\n",
    "# We now fix the energy axis for the counts map - (the reconstructed energy binning)\n",
    "config.datasets.geom.axes.energy.min = \"0.5 TeV\"\n",
    "config.datasets.geom.axes.energy.max = \"5 TeV\"\n",
    "config.datasets.geom.axes.energy.nbins = 10\n",
    "\n",
    "# We need to extract the ring for each observation separately, hence, no stacking at this stage\n",
    "config.datasets.stack = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the reduced dataset\n",
    "We now use the config file to do the initial data reduction which will then be used for a ring extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# create the config\n",
    "analysis = Analysis(config)\n",
    "\n",
    "# for this specific case,w e do not need fine bins in true energy\n",
    "analysis.config.datasets.geom.axes.energy_true = (\n",
    "    analysis.config.datasets.geom.axes.energy\n",
    ")\n",
    "\n",
    "# `First get the required observations\n",
    "analysis.get_observations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(analysis.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Data extraction\n",
    "analysis.get_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the ring background\n",
    "\n",
    "Since the ring background is extracted from real off events, we need to use the wstat statistics in this case. For this, we will use the `MapDatasetOnOFF` and the `RingBackgroundMaker` classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create exclusion mask\n",
    "First, we need to create an exclusion mask on the known sources. In this case, we need to mask only `MSH 15-52` but this depends on the sources present in our field of view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the geom that we use\n",
    "geom = analysis.datasets[0].counts.geom\n",
    "energy_axis = analysis.datasets[0].counts.geom.get_axis_by_name(\"energy\")\n",
    "geom_image = geom.to_image().to_cube([energy_axis.squash()])\n",
    "\n",
    "# Make the exclusion mask\n",
    "regions = CircleSkyRegion(center=source_pos, radius=0.3 * u.deg)\n",
    "exclusion_mask = Map.from_geom(geom_image)\n",
    "exclusion_mask.data = geom_image.region_mask([regions], inside=False)\n",
    "exclusion_mask.sum_over_axes().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the present analysis, we use a ring with an inner radius of 0.5 deg and width of 0.3 deg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ring_maker = RingBackgroundMaker(\n",
    "    r_in=\"0.5 deg\", width=\"0.3 deg\", exclusion_mask=exclusion_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a stacked dataset\n",
    "Now, we extract the background for each dataset and then stack the maps together to create a sinngle stacked map for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "stacked_on_off = MapDatasetOnOff.create(geom=geom_image)\n",
    "for dataset in analysis.datasets:\n",
    "    dataset_image = (\n",
    "        dataset.to_image()\n",
    "    )  # Ring extracting makes sense only for 2D analysis\n",
    "    dataset_on_off = ring_maker.run(dataset_image)\n",
    "    stacked_on_off.stack(dataset_on_off)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `stacked_on_off` has `on` and `off` counts and acceptance maps which we will use in all further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stacked_on_off)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Li&Ma maps\n",
    "We need to convolve our maps with an apprpriate smoothing kernel. Since astropy convolution kernels only accept integers, we first convert our required size in degrees to int depending on our pixel size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = geom.pixel_scales[0].to(\"deg\")\n",
    "# Using a convolution radius of 0.04 degrees\n",
    "theta = 0.04 * u.deg / scale\n",
    "tophat = Tophat2DKernel(theta)\n",
    "tophat.normalize(\"peak\")\n",
    "\n",
    "lima_maps = compute_lima_on_off_image(\n",
    "    stacked_on_off.counts,\n",
    "    stacked_on_off.counts_off,\n",
    "    stacked_on_off.acceptance,\n",
    "    stacked_on_off.acceptance_off,\n",
    "    tophat,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_map = lima_maps[\"significance\"]\n",
    "excess_map = lima_maps[\"excess\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can plot the excess and significance maps\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax1 = plt.subplot(221, projection=significance_map.geom.wcs)\n",
    "ax2 = plt.subplot(222, projection=excess_map.geom.wcs)\n",
    "\n",
    "ax1.set_title(\"Significance map\")\n",
    "significance_map.get_image_by_idx((0,)).plot(ax=ax1, add_cbar=True)\n",
    "\n",
    "ax2.set_title(\"Excess map\")\n",
    "excess_map.get_image_by_idx((0,)).plot(ax=ax2, add_cbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often important to look at the signficance distribution outside the exclusion region to understand if the exclusion regions were properly estimated.\n",
    "Typically, we expect the off distribution to be a standard normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 2D mask for the images\n",
    "significance_map_off = significance_map * exclusion_mask\n",
    "significance_all = significance_map.data[np.isfinite(significance_map.data)]\n",
    "significance_off = significance_map_off.data[\n",
    "    np.isfinite(significance_map_off.data)\n",
    "]\n",
    "\n",
    "plt.hist(\n",
    "    significance_all,\n",
    "    density=True,\n",
    "    alpha=0.5,\n",
    "    color=\"red\",\n",
    "    label=\"all bins\",\n",
    "    bins=21,\n",
    ")\n",
    "\n",
    "plt.hist(\n",
    "    significance_off,\n",
    "    density=True,\n",
    "    alpha=0.5,\n",
    "    color=\"blue\",\n",
    "    label=\"off bins\",\n",
    "    bins=21,\n",
    ")\n",
    "\n",
    "# Now, fit the off distribution with a Gaussian\n",
    "mu, std = norm.fit(significance_off)\n",
    "x = np.linspace(-8, 8, 50)\n",
    "p = norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, lw=2, color=\"black\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Significance\")\n",
    "plt.yscale(\"log\")\n",
    "plt.ylim(1e-5, 1)\n",
    "xmin, xmax = np.min(significance_all), np.max(significance_all)\n",
    "plt.xlim(xmin, xmax)\n",
    "\n",
    "print(f\"Fit results: mu = {mu:.2f}, std = {std:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
